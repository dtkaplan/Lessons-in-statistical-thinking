<!-- Topic28-03 -->
::: {.callout-note collapse="true" #enr-28-03}
## Multiple hypotheses (in Draft). 

The previous section showed the transformation from prior to posterior when there are only two hypotheses. But Bayesian thinking applies to situations with any number of hypotheses. 

Suppose we have $N$ hypotheses, which we will denote ${\cal H}_1, {\cal H}_2, \ldots, {\cal H}_N$.

Since there are multiple hypotheses, it's not clear how odds will apply. So instead of stating priors and posteriors as odds, we will write them as *relative probabilities*. We'll write the prior for each hypothesis as $prior({\cal H}_i)$ and the posterior as $posterior({\cal H}_i)$. 

Now an observation is made. Let's call it $\mathbb{X}$. This observation will drive the transformation of our priors into our posteriors. As before, the transformation involves the likelihood of $\mathbb{X}$ under the relative hypotheses. That is, ${\cal L}_{\cal H_i}(\mathbb{X})$. The calculation is simply

$$posterior({\cal H_i}) = {\cal L}_{\cal H_i}(\mathbb{X}) \times\ prior({\cal H_i}) \ \text{in relative probability form}$$

If you want to convert the posterior from a *relative probability* into an ordinary probability (between 0 and 1), you need to collect up the posteriors for all of the hypotheses. The notation $p(\cal H_i\given \mathbb X)$ is conventional, where the posterior nature of the probability is indicated by the $\given \mathbb X)$. Here's the formula:

$$p(\cal H_i\given \mathbb X) = \frac{posterior(\cal H_i)}{posterior(\cal H_1) + posterior(\cal H_2) + \cdots + posterior(\cal H_N)}$$

Example: Car safety Maybe move the example using the exponential distribution from the Likelihood Lesson to here.







Note: There are specialized methods of Bayesian statistics and whole courses on the topic. An excellent online course is [*Statistical Rethinking*](https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA).

:::
